{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgMaskGenerator(object):\n",
    "    def __init__(self,\n",
    "                 dirpath='./',\n",
    "                 img_w=1024, img_h=1024,\n",
    "                 batch_size=3,\n",
    "                 img_c = 3,\n",
    "                 verbose=1):\n",
    "        \n",
    "        # configurations    \n",
    "        self.HEIGHT     = img_h\n",
    "        self.WIDTH      = img_w\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.COLORS     = img_c\n",
    "        self.DIRPATH    = dirpath\n",
    "\n",
    "        \n",
    "    def prepare_data(self, verbose=1):\n",
    "        # check paths\n",
    "        self.IMAGES_DIR = os.path.join(self.DIRPATH, \"images\")\n",
    "        self.MASKS_DIR = os.path.join(self.DIRPATH, \"masks\")\n",
    "        if not os.path.exists(self.IMAGES_DIR):\n",
    "            raise Exception(\"Path not exists {}!\".format(self.IMAGES_DIR))\n",
    "        if not os.path.exists(self.MASKS_DIR):\n",
    "            raise Exception(\"Path not exists {}!\".format(self.MASKS_DIR))\n",
    "        \n",
    "        # dataset\n",
    "        ids = next(os.walk(self.IMAGES_DIR))[2] # list of names all images in the given path\n",
    "        \n",
    "        # Split on train and valid\n",
    "        self.ids_train, self.ids_valid = train_test_split(ids, test_size=0.1, random_state=66)\n",
    "        self.N_train = (len(self.ids_train) // self.BATCH_SIZE) + 1\n",
    "        self.N_valid = (len(self.ids_valid) // self.BATCH_SIZE) + 1\n",
    "        if verbose:\n",
    "            print(\"Train: \", self.N_train, \" * \", self.BATCH_SIZE)\n",
    "            print(\"Valid: \", self.N_valid, \" * \", self.BATCH_SIZE)\n",
    "    \n",
    "    def normalize(self, x_img, with_aug=False):\n",
    "        return resize(x_img, (self.WIDTH, self.HEIGHT, self.COLORS))\n",
    "    \n",
    "    def load_all_data(self, mode=\"valid\"):\n",
    "        assert mode in [\"train\", \"valid\"]\n",
    "        buff = []\n",
    "        if mode == \"train\":\n",
    "            self.ids = self.ids_train\n",
    "        else:\n",
    "            self.ids = self.ids_valid\n",
    "        \n",
    "        self.ids = self.ids_valid\n",
    "        X = np.zeros((len(self.ids), self.HEIGHT, self.WIDTH, self.COLORS), dtype=np.float32)\n",
    "        y = np.zeros((len(self.ids), self.HEIGHT, self.WIDTH, 1), dtype=np.float32) \n",
    "        \n",
    "        for n, _id in enumerate(self.ids):\n",
    "            # Load images\n",
    "            img = load_img(os.path.join(self.IMAGES_DIR, _id))\n",
    "            x_img = img_to_array(img)\n",
    "            x_img = self.normalize(x_img)\n",
    "\n",
    "            # Load masks\n",
    "            mask = img_to_array(load_img(os.path.join(self.MASKS_DIR, _id), grayscale=True))\n",
    "            mask = resize(mask, (self.WIDTH, self.HEIGHT, 1), mode = 'constant', preserve_range = True)\n",
    "            # Save images\n",
    "            X[n] = x_img/255.0\n",
    "            y[n] = mask/255.0\n",
    "            \n",
    "        return X, y\n",
    "        \n",
    "    def generator(self, partSize=10, mode=\"train\"): \n",
    "        assert mode in [\"train\", \"valid\"]\n",
    "        buff = []\n",
    "        if mode == \"train\":\n",
    "            self.ids = self.ids_train\n",
    "        else:\n",
    "            self.ids = self.ids_valid\n",
    "        \n",
    "        parts = []\n",
    "        buff = []\n",
    "        X = np.zeros((self.BATCH_SIZE, self.HEIGHT, self.WIDTH, self.COLORS), dtype=np.float32)\n",
    "        y = np.zeros((self.BATCH_SIZE, self.HEIGHT, self.WIDTH, 1), dtype=np.float32)    \n",
    "        while True:\n",
    "            for x in self.ids:\n",
    "                buff.append(x)\n",
    "                if len(buff) == self.BATCH_SIZE:\n",
    "                    # do\n",
    "                    for n, _id in enumerate(buff):\n",
    "                        # Load images\n",
    "                        img = load_img(os.path.join(self.IMAGES_DIR, _id))\n",
    "                        x_img = img_to_array(img)\n",
    "                        x_img = self.normalize(x_img)\n",
    "                        \n",
    "                        # Load masks\n",
    "                        mask = img_to_array(load_img(os.path.join(self.MASKS_DIR, _id), grayscale=True))\n",
    "                        mask = resize(mask, (self.WIDTH, self.HEIGHT, 1), mode = 'constant', preserve_range = True)\n",
    "                        # Save images\n",
    "                        X[n] = x_img/255.0\n",
    "                        y[n] = mask/255.0\n",
    "                    parts.append((X, y))\n",
    "                    if len(parts) == partSize:\n",
    "                        for part in parts:\n",
    "                            yield part\n",
    "                        parts = []\n",
    "                        \n",
    "                    # to default \n",
    "                    X = np.zeros((self.BATCH_SIZE, self.HEIGHT, self.WIDTH, self.COLORS), dtype=np.float32)\n",
    "                    y = np.zeros((self.BATCH_SIZE, self.HEIGHT, self.WIDTH, 1), dtype=np.float32)\n",
    "                    buff = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(ImgMaskGenerator):\n",
    "    def __init__(self, config={}):\n",
    "        # configurations    \n",
    "        self.HEIGHT     = config.get(\"img_h\", 1024)\n",
    "        self.WIDTH      = config.get(\"img_w\", 1024)\n",
    "        self.BATCH_SIZE = config.get(\"batch_size\", 3)\n",
    "        self.COLORS     = config.get(\"img_c\", 3)\n",
    "        \n",
    "        self.EPOCHS     = config.get(\"epochs\", 50)\n",
    "\n",
    "    def conv2d_block(self, input_tensor, n_filters, kernel_size = 3, batchnorm = True, colors=1):\n",
    "        \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "        # first layer\n",
    "        x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "                  kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        # second layer\n",
    "        x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "                  kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def get_unet(self, input_img, n_filters = 16, dropout = 0.1, batchnorm = True, colors=3):\n",
    "        \"\"\"Function to define the UNET Model\"\"\"\n",
    "        # Contracting Path\n",
    "        c1 = self.conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm, colors=colors)\n",
    "        p1 = MaxPooling2D((2, 2))(c1)\n",
    "        p1 = Dropout(dropout)(p1)\n",
    "\n",
    "        c2 = self.conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm, colors=colors)\n",
    "        p2 = MaxPooling2D((2, 2))(c2)\n",
    "        p2 = Dropout(dropout)(p2)\n",
    "\n",
    "        c3 = self.conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm, colors=colors)\n",
    "        p3 = MaxPooling2D((2, 2))(c3)\n",
    "        p3 = Dropout(dropout)(p3)\n",
    "\n",
    "        c4 = self.conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm, colors=colors)\n",
    "        p4 = MaxPooling2D((2, 2))(c4)\n",
    "        p4 = Dropout(dropout)(p4)\n",
    "\n",
    "        c5 = self.conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm, colors=colors)\n",
    "\n",
    "        # Expansive Path\n",
    "        u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "        u6 = concatenate([u6, c4])\n",
    "        u6 = Dropout(dropout)(u6)\n",
    "        c6 = self.conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "        u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "        u7 = concatenate([u7, c3])\n",
    "        u7 = Dropout(dropout)(u7)\n",
    "        c7 = self.conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "        u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "        u8 = concatenate([u8, c2])\n",
    "        u8 = Dropout(dropout)(u8)\n",
    "        c8 = self.conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "        u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "        u9 = concatenate([u9, c1])\n",
    "        u9 = Dropout(dropout)(u9)\n",
    "        c9 = self.conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "        outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "        model = Model(inputs=[input_img], outputs=[outputs])\n",
    "        return model\n",
    "    \n",
    "    def detect(self, imgs):\n",
    "        res = []\n",
    "        X = np.zeros((len(imgs), self.HEIGHT, self.WIDTH, self.COLORS), dtype=np.float32)\n",
    "        shapes = np.zeros((len(imgs), 3))\n",
    "        for i, img in enumerate(imgs):\n",
    "            X[i]      = self.normalize(img)\n",
    "            shapes[i] = np.array((img.shape[0], img.shape[1], 3))\n",
    "        preds = unet.model.predict(X)\n",
    "        \n",
    "        preds_t = (preds > 0.5).astype(np.uint8)\n",
    "        \n",
    "        preds_t_n = []\n",
    "        for pred, shape in zip(preds_t, shapes):    \n",
    "            pred = cv2.cvtColor(pred, cv2.COLOR_GRAY2RGB)*255\n",
    "            \n",
    "            # clear mask\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15)) # find coef\n",
    "            pred = cv2.morphologyEx(pred, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "            pred = resize(pred, shape).astype(np.float32)\n",
    "            \n",
    "            pred = cv2.cvtColor(pred*255, cv2.COLOR_RGB2GRAY)\n",
    "            \n",
    "            ret, thresh = cv2.threshold(pred.astype(np.uint8), 127, 255, 0)\n",
    "            contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            for i, c in enumerate(contours):\n",
    "                new_img = np.zeros(img.shape, np.uint8)\n",
    "                cv2.fillConvexPoly(new_img, np.array(cv2.convexHull(c), 'int32'), (255, 255, 255))\n",
    "                res.append(new_img)\n",
    "                \n",
    "        return res\n",
    "      #      self.PRED = pred\n",
    "      #      \n",
    "      #      preds_t_n.append([[[w] for w in h]for h in pred])\n",
    "      #\n",
    "      #  preds_t = (np.array(preds_t_n) > 0.5).astype(np.uint8)\n",
    "    #\n",
    "    #    UNP = [{\"masks\": pred.astype(bool)} for pred in preds_t]\n",
    "    #    return UNP\n",
    "    \n",
    "    def create_model(self):\n",
    "        input_img = Input((self.HEIGHT, self.WIDTH, self.COLORS), name='img')\n",
    "        self.model = self.get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "        self.model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        return self.model\n",
    "    \n",
    "    def prepare(self, dirpath, verbose=1):\n",
    "        self.DIRPATH = dirpath\n",
    "        self.prepare_data(verbose=verbose)\n",
    "        \n",
    "        self.train_gen = self.generator(mode=\"train\")\n",
    "        self.valid_gen = self.generator(mode=\"valid\")\n",
    "        \n",
    "    def fit(self, tmp_path='./tmp_model.h5', epochs=None, verbose=1):\n",
    "        self.callbacks = [\n",
    "            EarlyStopping(patience=20, verbose=verbose),\n",
    "            ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=verbose),\n",
    "            ModelCheckpoint(tmp_path, verbose=verbose, save_best_only=True, save_weights_only=True)\n",
    "        ]\n",
    "        return self.model.fit_generator(    self.train_gen, \n",
    "                      steps_per_epoch     = self.N_train, \n",
    "                      epochs              = epochs or self.EPOCHS, \n",
    "                      verbose             = verbose, \n",
    "                      callbacks           = self.callbacks, \n",
    "                      validation_data     = self.valid_gen, \n",
    "                      validation_steps    = self.N_valid)\n",
    "    \n",
    "    def load_last(self, tmp_path='./tmp_model.h5'):\n",
    "        self.model.load_weights(tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0531 18:32:59.313473 140024001517184 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0531 18:32:59.320867 140024001517184 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0531 18:32:59.321406 140024001517184 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0531 18:32:59.334396 140024001517184 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0531 18:32:59.334712 140024001517184 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0531 18:33:00.317690 140024001517184 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0531 18:33:00.329155 140024001517184 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/moving_averages.py:212: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0531 18:33:00.401821 140024001517184 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0531 18:33:00.405152 140024001517184 deprecation.py:506] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0531 18:33:01.375824 140024001517184 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0531 18:33:01.380074 140024001517184 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:3378: The name tf.nn.sigmoid_cross_entropy_with_logits is deprecated. Please use tf.nn.sigmoid_cross_entropy_with_logits instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  3326  *  3\n",
      "Valid:  370  *  3\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIR = \"./dataset\" \n",
    "\n",
    "unet = UNET({\"epochs\": 100})\n",
    "unet.create_model()\n",
    "unet.prepare(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/keras_preprocessing/image/utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 608/3326 [====>.........................] - ETA: 17:23 - loss: 0.1385 - acc: 0.9809"
     ]
    }
   ],
   "source": [
    "results = unet.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.load_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = unet.load_all_data(mode=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set (this must be equals to the best log_loss)\n",
    "unet.model.evaluate(X, y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict val\n",
    "preds = unet.model.predict(X, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold predictions\n",
    "preds_t = (preds > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
    "    \"\"\"Function to plot the results\"\"\"\n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "\n",
    "    has_mask = y[ix].max() > 0\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix, ...])\n",
    "    if has_mask:\n",
    "        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[0].set_title('Orig')\n",
    "\n",
    "    ax[1].imshow(y[ix].squeeze())\n",
    "    ax[1].set_title('Np')\n",
    "\n",
    "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n",
    "    if has_mask:\n",
    "        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[2].set_title('NP Predicted')\n",
    "    \n",
    "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)\n",
    "    if has_mask:\n",
    "        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[3].set_title('NP Predicted binary');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Check if training data looks all right\n",
    "plot_sample(X, y, preds, preds_t, ix=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffledSimplePipeline(Pipeline):\n",
    "    def __init__(self, batch_size, num_threads, device_id):\n",
    "        super(ShuffledSimplePipeline, self).__init__(batch_size, num_threads, device_id, seed = 12)\n",
    "        self.input = ops.FileReader(file_root = image_dir, random_shuffle = True, initial_fill = 21)\n",
    "        self.decode = ops.HostDecoder(output_type = types.RGB)\n",
    "\n",
    "    def define_graph(self):\n",
    "        jpegs, labels = self.input()\n",
    "        images = self.decode(jpegs)\n",
    "        return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "\n",
    "class GPUPipeline(Pipeline):\n",
    "    def __init__(self, image_dir, batch_size, num_threads, device_id):\n",
    "        super(GPUPipeline, self).__init__(batch_size, num_threads, device_id, seed = 12)\n",
    "        self.input = ops.FileReader(file_root = image_dir, random_shuffle = True, initial_fill = 21)\n",
    "        self.decode = ops.HostDecoder(output_type = types.RGB)\n",
    "        self.rotate = ops.Rotate(device = \"gpu\")\n",
    "        self.rng = ops.Uniform(range = (-10.0, 10.0))\n",
    "\n",
    "    def define_graph(self):\n",
    "        jpegs, labels = self.input()\n",
    "        images = self.decode(jpegs)\n",
    "        angle = self.rng()\n",
    "        rotated_images = self.rotate(images.gpu(), angle = angle)\n",
    "        return (rotated_images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = GPUPipeline(\"dataset\", 32, 1, 0)\n",
    "pipe.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = pipe.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images.as_cpu().at(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
