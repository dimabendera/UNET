{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "import imageio\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "class ImgMaskGenerator(object):\n",
    "    def __init__(self,\n",
    "                 dirpath='./',\n",
    "                 img_w=None, img_h=None,\n",
    "                 batch_size=3,\n",
    "                 img_c = 3,\n",
    "                 verbose=1):\n",
    "        \n",
    "        # configurations    \n",
    "        self.HEIGHT     = img_h\n",
    "        self.WIDTH      = img_w\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.COLORS     = img_c\n",
    "        self.DIRPATH    = dirpath\n",
    "    \n",
    "    def augaug(self, partSize = 100):\n",
    "        ia.seed(1)\n",
    "        images = []\n",
    "        segmaps = []\n",
    "        \n",
    "        self.ids = self.ids_train + self.ids_valid\n",
    "        for n, _id in enumerate(self.ids):\n",
    "            print(n, _id)\n",
    "            # Load images\n",
    "            img = load_img(os.path.join(self.IMAGES_DIR, _id))\n",
    "            images.append(img_to_array(img))\n",
    "    \n",
    "\n",
    "            # Load masks\n",
    "            mask = img_to_array(load_img(os.path.join(self.MASKS_DIR, _id)))\n",
    "            \n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15)) # find coef\n",
    "            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "            \n",
    "            rhash = random.getrandbits(128)      \n",
    "            mpimg.imsave(\"augdataset/images/{}.jpeg\".format(rhash), x_img/255)\n",
    "            mpimg.imsave(\"augdataset/masks/{}.jpeg\".format(rhash), mask/255)\n",
    "            \n",
    "            segmaps.append(mask)\n",
    "            \n",
    "            if len(images) == partSize:\n",
    "                augmenters_imgs = [\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-45, 45),\n",
    "                        shear=(-16, 16),\n",
    "                        order=[0, 1]\n",
    "                        #cval=(0, 255),\n",
    "                        #mode=ia.ALL\n",
    "                    ),\n",
    "                    iaa.Crop(px=(0, 10)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "                    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "                    iaa.GaussianBlur(sigma=(0, 3.0)) # blur images with a sigma of 0 to 3.0\n",
    "                ]      \n",
    "                \n",
    "                seq_imgs = iaa.Sequential(augmenters_imgs, random_order=False)        \n",
    "                seq_imgs_deterministic = seq_imgs.to_deterministic()\n",
    "                \n",
    "\n",
    "                imgs_aug = seq_imgs_deterministic.augment_images(images)\n",
    "                \n",
    "                masks_aug = seq_imgs_deterministic.augment_images(segmaps)\n",
    "                \n",
    "                \n",
    "                for ima, ma in zip(imgs_aug, masks_aug):\n",
    "                    rhash = random.getrandbits(128)\n",
    "                    \n",
    "                    mpimg.imsave(\"augdataset/images/{}.jpeg\".format(rhash), ima/255)\n",
    "                    mpimg.imsave(\"augdataset/masks/{}.jpeg\".format(rhash), ma/255)\n",
    "                \n",
    "                images  = []\n",
    "                segmaps = []\n",
    "        \n",
    "    def prepare_data(self, verbose=1):\n",
    "        # check paths\n",
    "        self.IMAGES_DIR = os.path.join(self.DIRPATH, \"images\")\n",
    "        self.MASKS_DIR = os.path.join(self.DIRPATH, \"masks\")\n",
    "        if not os.path.exists(self.IMAGES_DIR):\n",
    "            raise Exception(\"Path not exists {}!\".format(self.IMAGES_DIR))\n",
    "        if not os.path.exists(self.MASKS_DIR):\n",
    "            raise Exception(\"Path not exists {}!\".format(self.MASKS_DIR))\n",
    "        \n",
    "        # dataset\n",
    "        ids = next(os.walk(self.IMAGES_DIR))[2] # list of names all images in the given path\n",
    "        \n",
    "        # Split on train and valid\n",
    "        self.ids_train, self.ids_valid = train_test_split(ids, test_size=0.05, random_state=66)\n",
    "        self.N_train = (len(self.ids_train) // self.BATCH_SIZE) + 1\n",
    "        self.N_valid = (len(self.ids_valid) // self.BATCH_SIZE) + 1\n",
    "        if verbose:\n",
    "            print(\"Train: \", self.N_train, \" * \", self.BATCH_SIZE)\n",
    "            print(\"Valid: \", self.N_valid, \" * \", self.BATCH_SIZE)\n",
    "    \n",
    "    def normalize(self, x_img):\n",
    "        return resize(x_img, (self.HEIGHT, self.WIDTH, self.COLORS))\n",
    "    \n",
    "    def load_all_data(self, mode=\"valid\"):\n",
    "        assert mode in [\"train\", \"valid\"]\n",
    "        buff = []\n",
    "        if mode == \"train\":\n",
    "            self.ids = self.ids_train\n",
    "        else:\n",
    "            self.ids = self.ids_valid\n",
    "        \n",
    "        self.ids = self.ids_valid\n",
    "        X = np.zeros((len(self.ids), self.HEIGHT, self.WIDTH, self.COLORS), dtype=np.float32)\n",
    "        y = np.zeros((len(self.ids), self.HEIGHT, self.WIDTH, 2), dtype=np.float32) \n",
    "        \n",
    "        for n, _id in enumerate(self.ids):\n",
    "            # Load images\n",
    "            img = load_img(os.path.join(self.IMAGES_DIR, _id))\n",
    "            x_img = img_to_array(img)\n",
    "            x_img = self.normalize(x_img)\n",
    "\n",
    "            # Load masks\n",
    "            mask = img_to_array(load_img(os.path.join(self.MASKS_DIR, _id), grayscale=True))\n",
    "            mask = resize(mask, (self.HEIGHT, self.WIDTH, 1), mode = 'constant', preserve_range = True)\n",
    "            # Save images\n",
    "            X[n] = x_img/255.0\n",
    "            y[n] = mask/255.0\n",
    "            \n",
    "        return X, y\n",
    "        \n",
    "    def generator(self, partSize=20, mode=\"train\"):\n",
    "        assert mode in [\"train\", \"valid\"]\n",
    "            \n",
    "        buff = []\n",
    "        if mode == \"train\":\n",
    "            self.ids = self.ids_train\n",
    "        else:\n",
    "            self.ids = self.ids_valid\n",
    "        \n",
    "        parts = []\n",
    "        buff = []\n",
    "        X = np.zeros((self.BATCH_SIZE, self.HEIGHT, self.WIDTH, self.COLORS), dtype=np.float32)\n",
    "        y = np.zeros((self.BATCH_SIZE, self.HEIGHT, self.WIDTH, 2), dtype=np.float32)    \n",
    "        while True:\n",
    "            for x in self.ids:\n",
    "                buff.append(x)\n",
    "                if len(buff)  == self.BATCH_SIZE:\n",
    "                    for n, _id in enumerate(buff):\n",
    "                        # Load images\n",
    "                        img = load_img(os.path.join(self.IMAGES_DIR, _id))\n",
    "                        \n",
    "                        try:\n",
    "                            x_img = img_to_array(img)\n",
    "                        except:\n",
    "                            print(\"ERROR: \",buff)\n",
    "                            break\n",
    "                            buff = []\n",
    "                            \n",
    "                        mask = img_to_array(load_img(os.path.join(self.MASKS_DIR, _id), grayscale=True))\n",
    "                        \n",
    "                        x_img = self.normalize(x_img)\n",
    "            \n",
    "                        # Load masks\n",
    "                        mask = resize(mask, (self.HEIGHT, self.WIDTH, 1), mode = 'constant', preserve_range = True)\n",
    "                        # Save images\n",
    "                        X[n] = x_img/255.0\n",
    "                        #print(keras.utils.to_categorical(mask/255.0, num_classes=2).shape)\n",
    "                        #print((mask/255.0).shape)\n",
    "                        #print((y[n]).shape)\n",
    "                        y[n] = keras.utils.to_categorical(mask/255.0, num_classes=2)\n",
    "                        #print(mask)\n",
    "                        \n",
    "                    parts.append((X, y))\n",
    "                    if len(parts) > partSize:\n",
    "                        for part in parts:\n",
    "                            yield part\n",
    "                        parts = []\n",
    "                        \n",
    "                    # to default \n",
    "                    X = np.zeros((self.BATCH_SIZE, self.HEIGHT, self.WIDTH, self.COLORS), dtype=np.float32)\n",
    "                    y = np.zeros((self.BATCH_SIZE, self.HEIGHT, self.WIDTH, 2), dtype=np.float32)\n",
    "                    buff = []\n",
    "                    \n",
    "class SDetector(ImgMaskGenerator):\n",
    "    def __init__(self, config={}):\n",
    "        # configurations    \n",
    "        self.HEIGHT     = config.get(\"img_h\", 32*48)\n",
    "        self.WIDTH      = config.get(\"img_w\", 32*48)\n",
    "        self.BATCH_SIZE = config.get(\"batch_size\", 5)\n",
    "        self.COLORS     = config.get(\"img_c\", 3)\n",
    "        \n",
    "        self.EPOCHS     = config.get(\"epochs\", 50)\n",
    "        self.COUNT_CATEGORIES = config.get(\"count_categories\", 2)\n",
    "        \n",
    "    def conv_block(self, inputs, conv_type, kernel, kernel_size, strides, padding='same', relu=True):\n",
    "        if(conv_type == 'ds'):\n",
    "            x = keras.layers.SeparableConv2D(kernel, kernel_size, padding=padding, strides = strides)(inputs)\n",
    "        else:\n",
    "            x = keras.layers.Conv2D(kernel, kernel_size, padding=padding, strides = strides)(inputs)  \n",
    "\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        if (relu):\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def _res_bottleneck(self, inputs, filters, kernel, t, s, r=False):\n",
    "        tchannel = keras.backend.int_shape(inputs)[-1] * t\n",
    "\n",
    "        x = self.conv_block(inputs, 'conv', tchannel, (1, 1), strides=(1, 1))\n",
    "\n",
    "        x = keras.layers.DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "        x = self.conv_block(x, 'conv', filters, (1, 1), strides=(1, 1), padding='same', relu=False)\n",
    "\n",
    "        if r:\n",
    "            x = keras.layers.add([x, inputs])\n",
    "        return x\n",
    "    \n",
    "    def bottleneck_block(self, inputs, filters, kernel, t, strides, n):\n",
    "        x = self._res_bottleneck(inputs, filters, kernel, t, strides)\n",
    "        for i in range(1, n):\n",
    "            x = self._res_bottleneck(x, filters, kernel, t, 1, True)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def pyramid_pooling_block(self, input_tensor, bin_sizes, w, h):\n",
    "        concat_list = [input_tensor]\n",
    "\n",
    "        for bin_size in bin_sizes:\n",
    "            pool_strides_size=(w//bin_size, h//bin_size)\n",
    "\n",
    "            x = keras.layers.AveragePooling2D(pool_size=pool_strides_size, strides=pool_strides_size)(input_tensor)\n",
    "            x = keras.layers.Conv2D(128, 3, strides=2, padding='same')(x)\n",
    "            x = keras.layers.Lambda(lambda x: keras.backend.tf.image.resize_images(x, (w,h)))(x)\n",
    "\n",
    "            concat_list.append(x)\n",
    "\n",
    "        return keras.layers.concatenate(concat_list)\n",
    "\n",
    "    def get_scnn(self, input_layer, h, w):\n",
    "        \"\"\"Function to define the SCNN Model\"\"\"\n",
    "        assert h%32 == 0\n",
    "        assert w%32 == 0\n",
    "        \n",
    "        lds_layer = self.conv_block(input_layer, 'conv', w//32, (3, 3), strides = (2, 2))\n",
    "        lds_layer = self.conv_block(lds_layer, 'ds', w//32 + (w//32)//2, (3, 3), strides = (2, 2))\n",
    "        lds_layer = self.conv_block(lds_layer, 'ds', 2*(w//32), (3, 3), strides = (2, 2))\n",
    "\n",
    "        gfe_layer = self.bottleneck_block(lds_layer, h//32, (3, 3), t=6, strides=2, n=3)\n",
    "        gfe_layer = self.bottleneck_block(gfe_layer, h//32 + (h//32)//2, (3, 3), t=6, strides=2, n=3)\n",
    "        gfe_layer = self.bottleneck_block(gfe_layer, 2*(h//32), (3, 3), t=6, strides=1, n=3)\n",
    "        gfe_layer = self.pyramid_pooling_block(gfe_layer, [2,4,6,8], h//32, w//32)\n",
    "\n",
    "        ff_layer1 = self.conv_block(lds_layer, 'conv', 2*(h//32), (1,1), padding='same', strides= (1,1), relu=False)\n",
    "        ff_layer2 = keras.layers.UpSampling2D((4, 4))(gfe_layer)\n",
    "        ff_layer2 = keras.layers.SeparableConv2D(2*(h//32), (3, 3), padding='same', strides = (1, 1), activation=None, dilation_rate=(4, 4))(ff_layer2)\n",
    "\n",
    "        ff_final = keras.layers.add([ff_layer1, ff_layer2])\n",
    "        ff_final = keras.layers.BatchNormalization()(ff_final)\n",
    "        ff_final = keras.layers.Activation('relu')(ff_final)\n",
    "\n",
    "        classifier = keras.layers.SeparableConv2D(2*(h//32), (3, 3), padding='same', strides = (1, 1), name = 'DSConv1_classifier')(ff_final)\n",
    "        classifier = keras.layers.BatchNormalization()(classifier)\n",
    "        classifier = keras.layers.Activation('relu')(classifier)\n",
    "\n",
    "        classifier = keras.layers.SeparableConv2D(2*(h//32), (3, 3), padding='same', strides = (1, 1), name = 'DSConv2_classifier')(classifier)\n",
    "        classifier = keras.layers.BatchNormalization()(classifier)\n",
    "        classifier = keras.layers.Activation('relu')(classifier)\n",
    "\n",
    "        classifier = self.conv_block(classifier, 'conv', self.COUNT_CATEGORIES, (1, 1), strides=(1, 1), padding='same', relu=True)\n",
    "\n",
    "        classifier = keras.layers.Dropout(0.3)(classifier)\n",
    "\n",
    "        classifier = keras.layers.UpSampling2D((8, 8))(classifier)\n",
    "        classifier = keras.layers.Activation('softmax')(classifier)\n",
    "\n",
    "        self.model = keras.Model(inputs = input_layer , outputs = classifier, name = 'Fast_SCNN')\n",
    "   \n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, imgs, shapes):\n",
    "        X = np.zeros((len(imgs), self.HEIGHT, self.WIDTH, self.COLORS), dtype=np.float32)\n",
    "        for i, img in enumerate(imgs):\n",
    "            X[i]      = self.normalize(img)\n",
    "            \n",
    "            #print(X[i])\n",
    "            plt.imshow(X[i])\n",
    "            plt.show()\n",
    "            \n",
    "            shapes[i] = np.array((img.shape[0], img.shape[1], 3))\n",
    "     \n",
    "        preds = self.model.predict(X)\n",
    "        \n",
    "        preds_t = preds[:, :, :, 1:2].reshape((preds.shape[0],preds.shape[1], preds.shape[2]))\n",
    "        \n",
    "        return (preds_t > 0.2).astype(np.uint8)\n",
    "        \n",
    "    def detect(self, imgs):\n",
    "        shapes = np.zeros((len(imgs), 3))\n",
    "        preds_t = self.predict(imgs, shapes)\n",
    "        res = []\n",
    "        \n",
    "        for j, (pred, shape) in enumerate(zip(preds_t, shapes)):\n",
    "            img = imgs[j]\n",
    "            preds_t_n = []\n",
    "            \n",
    "            pred = cv2.cvtColor(pred, cv2.COLOR_GRAY2RGB)*255\n",
    "\n",
    "            # clear mask\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15)) # find coef\n",
    "            pred = cv2.morphologyEx(pred, cv2.MORPH_OPEN, kernel)\n",
    "            pred = cv2.morphologyEx(pred, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "            pred = resize(pred, shape).astype(np.float32)\n",
    "\n",
    "            pred = cv2.cvtColor(pred*255, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            ret, thresh = cv2.threshold(pred.astype(np.uint8), 127, 255, 0)\n",
    "            contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            for i, c in enumerate(contours):\n",
    "#                 if (cv2.contourArea(c)/(img.shape[0]*img.shape[1])) < 0.0035:\n",
    "#                     print(\"BAD AREA\")\n",
    "#                     # detect center\n",
    "#                     M = cv2.moments(c)\n",
    "#                     cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "#                     cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    \n",
    "#                     refineSize = 256\n",
    "#                     x1 = cX - refineSize if cX - refineSize > 0 else 0\n",
    "#                     y1 = cY - refineSize if cY - refineSize > 0 else 0\n",
    "                    \n",
    "#                     x2 = cX + refineSize if cX + refineSize < img.shape[1] else img.shape[1]\n",
    "#                     y2 = cY + refineSize if cY + refineSize < img.shape[0] else img.shape[0]\n",
    "    \n",
    "#                     small_img = img[y1:y2, x1:x2]\n",
    "                    \n",
    "#                     small_shapes = np.zeros((len(imgs), 3))\n",
    "#                     preds_t = self.predict([small_img], small_shapes)\n",
    "#                     pred = cv2.cvtColor(preds_t[0], cv2.COLOR_GRAY2RGB)*255\n",
    "#                     pred = cv2.morphologyEx(pred, cv2.MORPH_OPEN, kernel)\n",
    "                    \n",
    "#                     pred = cv2.morphologyEx(pred, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "#                     pred = resize(pred, small_shapes[0]).astype(np.float32)\n",
    "\n",
    "#                     pred = cv2.cvtColor(pred*255, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "#                     ret, thresh = cv2.threshold(pred.astype(np.uint8), 127, 255, 0)\n",
    "#                     contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    \n",
    "#                     #cv2.drawContours(small_img, contours, -1, (0, 255, 0), 2)\n",
    "#                     #plt.imshow(small_img)\n",
    "#                     #plt.show()\n",
    "#                     if len(contours):\n",
    "#                         c = contours[0]\n",
    "#                         c = np.array([[[ic[0][0] + x1, ic[0][1] + y1]] for ic in c])\n",
    "                           \n",
    "                new_img = np.zeros(img.shape, np.uint8)\n",
    "                cv2.fillConvexPoly(new_img, np.array(cv2.convexHull(c), 'int32'), (255, 255, 255))\n",
    "                preds_t_n.append(new_img)\n",
    "            res.append(preds_t_n)\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def create_model(self):\n",
    "        # Input Layer\n",
    "        input_layer = keras.layers.Input(shape=((self.HEIGHT, self.WIDTH, self.COLORS)), name = 'input_layer')\n",
    "        self.model = self.get_scnn(input_layer, self.HEIGHT, self.WIDTH)\n",
    "        \n",
    "        optimizer = keras.optimizers.SGD(momentum=0.9, lr=0.045)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    def prepare(self, dirpath, verbose=1):\n",
    "        self.DIRPATH = dirpath\n",
    "        self.prepare_data(verbose=verbose)\n",
    "        \n",
    "        self.train_gen = self.generator(mode=\"train\")\n",
    "        self.valid_gen = self.generator(mode=\"valid\")\n",
    "        \n",
    "    def fit(self, tmp_path='./tmp_scnn.h5', epochs=None, verbose=1):\n",
    "        self.callbacks = [\n",
    "            EarlyStopping(patience=20, verbose=verbose),\n",
    "            ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=verbose),\n",
    "            ModelCheckpoint(tmp_path, verbose=verbose, save_best_only=True, save_weights_only=True)\n",
    "        ]\n",
    "        return self.model.fit_generator(    self.train_gen, \n",
    "                      steps_per_epoch     = self.N_train, \n",
    "                      epochs              = epochs or self.EPOCHS, \n",
    "                      verbose             = verbose, \n",
    "                      callbacks           = self.callbacks, \n",
    "                      validation_data     = self.valid_gen, \n",
    "                      validation_steps    = self.N_valid)\n",
    "    \n",
    "    def load_last(self, tmp_path='./tmp_scnn.h5'):\n",
    "        self.model.load_weights(tmp_path)\n",
    "        \n",
    "    def save(self, path):\n",
    "        self.model.save(path)\n",
    "        return path\n",
    "\n",
    "    def load(self, path):\n",
    "        self.model = load_model(path)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QU9uETiqxOQW"
   },
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tkduqU9XQon4"
   },
   "source": [
    "![Fast-SCNN Architecture](https://github.com/DeepVoltaire/Fast-SCNN/raw/master/figures/fast-scnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBKpiNtQxMA6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0606 10:11:49.062182 140136009078400 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0606 10:11:49.070183 140136009078400 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0606 10:11:49.070744 140136009078400 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0606 10:11:49.083797 140136009078400 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0606 10:11:49.084109 140136009078400 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0606 10:11:50.069812 140136009078400 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0606 10:11:50.081217 140136009078400 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/moving_averages.py:212: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0606 10:11:51.664955 140136009078400 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0606 10:11:51.754395 140136009078400 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0606 10:11:51.972665 140136009078400 deprecation.py:506] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0606 10:11:51.991484 140136009078400 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detector = SDetector({\"epochs\": 100})\n",
    "model = detector.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4692
    },
    "colab_type": "code",
    "id": "1bb-xo4uNhxV",
    "outputId": "939a9301-77e9-4dba-cc6f-a25c2af7d797",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        (None, 1536, 1536, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 768, 768, 48) 1344        input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 768, 768, 48) 192         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 768, 768, 48) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 384, 384, 72) 3960        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 384, 384, 72) 288         separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 384, 384, 72) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 192, 192, 96) 7656        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 192, 192, 96) 384         separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 192, 192, 96) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 192, 192, 576 55872       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 192, 192, 576 2304        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 192, 192, 576 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_1 (DepthwiseCo (None, 96, 96, 576)  5760        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 96, 96, 576)  2304        depthwise_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 96, 96, 576)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 96, 96, 48)   27696       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 96, 96, 48)   192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 96, 96, 288)  14112       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 96, 96, 288)  1152        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 96, 96, 288)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_2 (DepthwiseCo (None, 96, 96, 288)  2880        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 96, 96, 288)  1152        depthwise_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 96, 96, 288)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 96, 96, 48)   13872       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 96, 96, 48)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 96, 96, 48)   0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 96, 96, 288)  14112       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 96, 96, 288)  1152        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 96, 96, 288)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_3 (DepthwiseCo (None, 96, 96, 288)  2880        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 96, 96, 288)  1152        depthwise_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 96, 96, 288)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 96, 96, 48)   13872       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 96, 96, 48)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 96, 96, 48)   0           batch_normalization_12[0][0]     \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 96, 96, 288)  14112       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 96, 96, 288)  1152        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 96, 96, 288)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_4 (DepthwiseCo (None, 48, 48, 288)  2880        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 48, 48, 288)  1152        depthwise_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 48, 48, 288)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 48, 48, 72)   20808       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 48, 48, 72)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 48, 48, 432)  31536       batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 48, 48, 432)  1728        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 48, 48, 432)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_5 (DepthwiseCo (None, 48, 48, 432)  4320        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 48, 48, 432)  1728        depthwise_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 48, 48, 432)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 48, 48, 72)   31176       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 48, 48, 72)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 48, 48, 72)   0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 48, 48, 432)  31536       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 48, 48, 432)  1728        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 48, 48, 432)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_6 (DepthwiseCo (None, 48, 48, 432)  4320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 48, 48, 432)  1728        depthwise_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 48, 48, 432)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 48, 48, 72)   31176       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 48, 48, 72)   288         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 48, 48, 72)   0           batch_normalization_21[0][0]     \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 48, 48, 432)  31536       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 48, 48, 432)  1728        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 48, 48, 432)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_7 (DepthwiseCo (None, 48, 48, 432)  4320        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 48, 48, 432)  1728        depthwise_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 48, 48, 432)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 48, 48, 96)   41568       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 48, 48, 96)   384         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 48, 48, 576)  55872       batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 48, 48, 576)  2304        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 48, 48, 576)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_8 (DepthwiseCo (None, 48, 48, 576)  5760        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 48, 48, 576)  2304        depthwise_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 48, 48, 576)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 48, 48, 96)   55392       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 48, 48, 96)   384         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 48, 48, 96)   0           batch_normalization_27[0][0]     \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 48, 48, 576)  55872       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 48, 48, 576)  2304        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 48, 48, 576)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_9 (DepthwiseCo (None, 48, 48, 576)  5760        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 48, 48, 576)  2304        depthwise_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 48, 48, 576)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 48, 48, 96)   55392       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 48, 48, 96)   384         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 48, 48, 96)   0           batch_normalization_30[0][0]     \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 2, 2, 96)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 96)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 6, 6, 96)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 8, 8, 96)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 1, 1, 128)    110720      average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 2, 2, 128)    110720      average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 3, 3, 128)    110720      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 4, 4, 128)    110720      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 48, 48, 128)  0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 48, 48, 128)  0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 48, 48, 128)  0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 48, 48, 128)  0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 48, 48, 608)  0           add_6[0][0]                      \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 192, 192, 96) 9312        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 192, 192, 608 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 192, 192, 96) 384         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 192, 192, 96) 63936       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 192, 192, 96) 0           batch_normalization_31[0][0]     \n",
      "                                                                 separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 192, 192, 96) 384         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 192, 192, 96) 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "DSConv1_classifier (SeparableCo (None, 192, 192, 96) 10176       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 192, 192, 96) 384         DSConv1_classifier[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 192, 192, 96) 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "DSConv2_classifier (SeparableCo (None, 192, 192, 96) 10176       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 192, 192, 96) 384         DSConv2_classifier[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 192, 192, 96) 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 192, 192, 2)  194         activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 192, 192, 2)  8           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 192, 192, 2)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 192, 192, 2)  0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 1536, 1536, 2 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 1536, 1536, 2 0           up_sampling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,220,130\n",
      "Trainable params: 1,202,078\n",
      "Non-trainable params: 18,052\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  996  *  5\n",
      "Valid:  53  *  5\n"
     ]
    }
   ],
   "source": [
    "detector.prepare(\"./augdataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/keras_preprocessing/image/utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606/996 [=================>............] - ETA: 9:09 - loss: 0.2418 - acc: 0.9930ERROR:  ['124392466832587191108470478552999670803.jpeg', '306201975525243325277531053009715617725.jpeg', '48297592656754822453500421004452274468.jpeg', '246932305217129385797641837258730749493.jpeg', '196690524000124057152127497671044985497.jpeg']\n",
      "996/996 [==============================] - 1455s 1s/step - loss: 0.2320 - acc: 0.9941 - val_loss: 0.0257 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02570, saving model to ./tmp_scnn.h5\n",
      "Epoch 2/100\n",
      "996/996 [==============================] - 1423s 1s/step - loss: 0.2132 - acc: 0.9956 - val_loss: 0.0136 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02570 to 0.01359, saving model to ./tmp_scnn.h5\n",
      "Epoch 3/100\n",
      "996/996 [==============================] - 1420s 1s/step - loss: 0.2117 - acc: 0.9956 - val_loss: 0.0116 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01359 to 0.01159, saving model to ./tmp_scnn.h5\n",
      "Epoch 4/100\n",
      "996/996 [==============================] - 1424s 1s/step - loss: 0.2113 - acc: 0.9956 - val_loss: 0.0116 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.01159\n",
      "Epoch 5/100\n",
      "996/996 [==============================] - 1423s 1s/step - loss: 0.2112 - acc: 0.9956 - val_loss: 0.0113 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01159 to 0.01132, saving model to ./tmp_scnn.h5\n",
      "Epoch 6/100\n",
      "996/996 [==============================] - 1425s 1s/step - loss: 0.2110 - acc: 0.9956 - val_loss: 0.0106 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01132 to 0.01060, saving model to ./tmp_scnn.h5\n",
      "Epoch 7/100\n",
      "996/996 [==============================] - 1407s 1s/step - loss: 0.2110 - acc: 0.9956 - val_loss: 0.0089 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01060 to 0.00890, saving model to ./tmp_scnn.h5\n",
      "Epoch 8/100\n",
      " 50/996 [>.............................] - ETA: 19:50 - loss: 0.2110 - acc: 0.9956"
     ]
    }
   ],
   "source": [
    "detector.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.load_last(tmp_path='./tmp_scnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/keras_preprocessing/image/utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "X, y = detector.load_all_data(mode=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop\n",
    "X, y = X[:20], y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.model.evaluate(X, y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = detector.model.predict(X, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_t = (preds > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds[:, :, :, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get second class\n",
    "preds_t = preds_t[:, :, :, 1:2] \n",
    "y = y[:, :, :, 1:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
    "    \"\"\"Function to plot the results\"\"\"\n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "\n",
    "    has_mask = y[ix].max() > 0\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix, ...])\n",
    "    if has_mask:\n",
    "        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[0].set_title('Orig')\n",
    "\n",
    "    ax[1].imshow(y[ix].squeeze())\n",
    "    ax[1].set_title('Np')\n",
    "\n",
    "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n",
    "    if has_mask:\n",
    "        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[2].set_title('NP Predicted')\n",
    "    \n",
    "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)\n",
    "    if has_mask:\n",
    "        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[3].set_title('NP Predicted binary');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Check if training data looks all right\n",
    "plot_sample(X, y, preds, preds_t, ix=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2048//32 + (2048//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TF 2.0 Fast-SCNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
