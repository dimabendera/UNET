{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "import imageio\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "class ImgMaskGenerator(object):\n",
    "    def __init__(self,\n",
    "                 dirpath='./',\n",
    "                 img_w=1024, img_h=1024 + 1024,\n",
    "                 batch_size=3,\n",
    "                 img_c = 3,\n",
    "                 verbose=1):\n",
    "        \n",
    "        # configurations    \n",
    "        self.HEIGHT     = img_h\n",
    "        self.WIDTH      = img_w\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.COLORS     = img_c\n",
    "        self.DIRPATH    = dirpath\n",
    "    \n",
    "    def augaug(self, partSize = 100):\n",
    "        ia.seed(1)\n",
    "        images = []\n",
    "        segmaps = []\n",
    "        \n",
    "        self.ids = self.ids_train + self.ids_valid\n",
    "        for n, _id in enumerate(self.ids):\n",
    "            print(n, _id)\n",
    "            # Load images\n",
    "            img = load_img(os.path.join(self.IMAGES_DIR, _id))\n",
    "            images.append(img_to_array(img))\n",
    "    \n",
    "\n",
    "            # Load masks\n",
    "            mask = img_to_array(load_img(os.path.join(self.MASKS_DIR, _id)))\n",
    "            \n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15)) # find coef\n",
    "            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "            \n",
    "            rhash = random.getrandbits(128)      \n",
    "            mpimg.imsave(\"augdataset/images/{}.jpeg\".format(rhash), x_img/255)\n",
    "            mpimg.imsave(\"augdataset/masks/{}.jpeg\".format(rhash), mask/255)\n",
    "            \n",
    "            segmaps.append(mask)\n",
    "            \n",
    "            if len(images) == partSize:\n",
    "                augmenters_imgs = [\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-45, 45),\n",
    "                        shear=(-16, 16),\n",
    "                        order=[0, 1]\n",
    "                        #cval=(0, 255),\n",
    "                        #mode=ia.ALL\n",
    "                    ),\n",
    "                    iaa.Crop(px=(0, 10)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "                    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "                    iaa.GaussianBlur(sigma=(0, 3.0)) # blur images with a sigma of 0 to 3.0\n",
    "                ]      \n",
    "                \n",
    "                seq_imgs = iaa.Sequential(augmenters_imgs, random_order=False)        \n",
    "                seq_imgs_deterministic = seq_imgs.to_deterministic()\n",
    "                \n",
    "\n",
    "                imgs_aug = seq_imgs_deterministic.augment_images(images)\n",
    "                \n",
    "                masks_aug = seq_imgs_deterministic.augment_images(segmaps)\n",
    "                \n",
    "                \n",
    "                for ima, ma in zip(imgs_aug, masks_aug):\n",
    "                    rhash = random.getrandbits(128)\n",
    "                    \n",
    "                    mpimg.imsave(\"augdataset/images/{}.jpeg\".format(rhash), ima/255)\n",
    "                    mpimg.imsave(\"augdataset/masks/{}.jpeg\".format(rhash), ma/255)\n",
    "                \n",
    "                images  = []\n",
    "                segmaps = []\n",
    "        \n",
    "    def prepare_data(self, verbose=1):\n",
    "        # check paths\n",
    "        self.IMAGES_DIR = os.path.join(self.DIRPATH, \"images\")\n",
    "        self.MASKS_DIR = os.path.join(self.DIRPATH, \"masks\")\n",
    "        if not os.path.exists(self.IMAGES_DIR):\n",
    "            raise Exception(\"Path not exists {}!\".format(self.IMAGES_DIR))\n",
    "        if not os.path.exists(self.MASKS_DIR):\n",
    "            raise Exception(\"Path not exists {}!\".format(self.MASKS_DIR))\n",
    "        \n",
    "        # dataset\n",
    "        ids = next(os.walk(self.IMAGES_DIR))[2] # list of names all images in the given path\n",
    "        \n",
    "        # Split on train and valid\n",
    "        self.ids_train, self.ids_valid = train_test_split(ids, test_size=0.05, random_state=66)\n",
    "        self.N_train = (len(self.ids_train) // self.BATCH_SIZE) + 1\n",
    "        self.N_valid = (len(self.ids_valid) // self.BATCH_SIZE) + 1\n",
    "        if verbose:\n",
    "            print(\"Train: \", self.N_train, \" * \", self.BATCH_SIZE)\n",
    "            print(\"Valid: \", self.N_valid, \" * \", self.BATCH_SIZE)\n",
    "    \n",
    "    def normalize(self, x_img):\n",
    "        return resize(x_img, (self.HEIGHT, self.WIDTH, self.COLORS))\n",
    "    \n",
    "    def load_all_data(self, mode=\"valid\"):\n",
    "        assert mode in [\"train\", \"valid\"]\n",
    "        buff = []\n",
    "        if mode == \"train\":\n",
    "            self.ids = self.ids_train\n",
    "        else:\n",
    "            self.ids = self.ids_valid\n",
    "        \n",
    "        self.ids = self.ids_valid\n",
    "        X = np.zeros((len(self.ids), self.HEIGHT, self.WIDTH, self.COLORS), dtype=np.float32)\n",
    "        y = np.zeros((len(self.ids), self.HEIGHT, self.WIDTH, 2), dtype=np.float32) \n",
    "        \n",
    "        for n, _id in enumerate(self.ids):\n",
    "            # Load images\n",
    "            img = load_img(os.path.join(self.IMAGES_DIR, _id))\n",
    "            x_img = img_to_array(img)\n",
    "            x_img = self.normalize(x_img)\n",
    "\n",
    "            # Load masks\n",
    "            mask = img_to_array(load_img(os.path.join(self.MASKS_DIR, _id), grayscale=True))\n",
    "            mask = resize(mask, (self.HEIGHT, self.WIDTH, 1), mode = 'constant', preserve_range = True)\n",
    "            # Save images\n",
    "            X[n] = x_img/255.0\n",
    "            y[n] = mask/255.0\n",
    "            \n",
    "        return X, y\n",
    "        \n",
    "    def generator(self, partSize=20, mode=\"train\"):\n",
    "        assert mode in [\"train\", \"valid\"]\n",
    "            \n",
    "        buff = []\n",
    "        if mode == \"train\":\n",
    "            self.ids = self.ids_train\n",
    "        else:\n",
    "            self.ids = self.ids_valid\n",
    "        \n",
    "        parts = []\n",
    "        buff = []\n",
    "        X = np.zeros((self.BATCH_SIZE, self.HEIGHT, self.WIDTH, self.COLORS), dtype=np.float32)\n",
    "        y = np.zeros((self.BATCH_SIZE, self.HEIGHT, self.WIDTH, 2), dtype=np.float32)    \n",
    "        while True:\n",
    "            for x in self.ids:\n",
    "                buff.append(x)\n",
    "                if len(buff)  == self.BATCH_SIZE:\n",
    "                    for n, _id in enumerate(buff):\n",
    "                        # Load images\n",
    "                        img = load_img(os.path.join(self.IMAGES_DIR, _id))\n",
    "                        \n",
    "                        try:\n",
    "                            x_img = img_to_array(img)\n",
    "                        except:\n",
    "                            print(\"ERROR: \",buff)\n",
    "                            break\n",
    "                            buff = []\n",
    "                            \n",
    "                        mask = img_to_array(load_img(os.path.join(self.MASKS_DIR, _id), grayscale=True))\n",
    "                        \n",
    "                        x_img = self.normalize(x_img)\n",
    "            \n",
    "                        # Load masks\n",
    "                        mask = resize(mask, (self.HEIGHT, self.WIDTH, 1), mode = 'constant', preserve_range = True)\n",
    "                        # Save images\n",
    "                        X[n] = x_img/255.0\n",
    "                        #print(keras.utils.to_categorical(mask/255.0, num_classes=2).shape)\n",
    "                        #print((mask/255.0).shape)\n",
    "                        #print((y[n]).shape)\n",
    "                        y[n] = keras.utils.to_categorical(mask/255.0, num_classes=2)\n",
    "                        #print(mask)\n",
    "                        \n",
    "                    parts.append((X, y))\n",
    "                    if len(parts) > partSize:\n",
    "                        for part in parts:\n",
    "                            yield part\n",
    "                        parts = []\n",
    "                        \n",
    "                    # to default \n",
    "                    X = np.zeros((self.BATCH_SIZE, self.HEIGHT, self.WIDTH, self.COLORS), dtype=np.float32)\n",
    "                    y = np.zeros((self.BATCH_SIZE, self.HEIGHT, self.WIDTH, 2), dtype=np.float32)\n",
    "                    buff = []\n",
    "                    \n",
    "class SDetector(ImgMaskGenerator):\n",
    "    def __init__(self, config={}):\n",
    "        # configurations    \n",
    "        self.HEIGHT     = config.get(\"img_h\", 1024 + 1024)\n",
    "        self.WIDTH      = config.get(\"img_w\", 1024)\n",
    "        self.BATCH_SIZE = config.get(\"batch_size\", 3)\n",
    "        self.COLORS     = config.get(\"img_c\", 3)\n",
    "        \n",
    "        self.EPOCHS     = config.get(\"epochs\", 50)\n",
    "        self.COUNT_CATEGORIES = config.get(\"count_categories\", 2)\n",
    "        \n",
    "    def conv_block(self, inputs, conv_type, kernel, kernel_size, strides, padding='same', relu=True):\n",
    "        if(conv_type == 'ds'):\n",
    "            x = keras.layers.SeparableConv2D(kernel, kernel_size, padding=padding, strides = strides)(inputs)\n",
    "        else:\n",
    "            x = keras.layers.Conv2D(kernel, kernel_size, padding=padding, strides = strides)(inputs)  \n",
    "\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        if (relu):\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def _res_bottleneck(self, inputs, filters, kernel, t, s, r=False):\n",
    "        tchannel = keras.backend.int_shape(inputs)[-1] * t\n",
    "\n",
    "        x = self.conv_block(inputs, 'conv', tchannel, (1, 1), strides=(1, 1))\n",
    "\n",
    "        x = keras.layers.DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "        x = self.conv_block(x, 'conv', filters, (1, 1), strides=(1, 1), padding='same', relu=False)\n",
    "\n",
    "        if r:\n",
    "            x = keras.layers.add([x, inputs])\n",
    "        return x\n",
    "    \n",
    "    def bottleneck_block(self, inputs, filters, kernel, t, strides, n):\n",
    "        x = self._res_bottleneck(inputs, filters, kernel, t, strides)\n",
    "        for i in range(1, n):\n",
    "            x = self._res_bottleneck(x, filters, kernel, t, 1, True)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def pyramid_pooling_block(self, input_tensor, bin_sizes):\n",
    "        concat_list = [input_tensor]\n",
    "        w = 64\n",
    "        h = 32\n",
    "\n",
    "        for bin_size in bin_sizes:\n",
    "            pool_strides_size=(w//bin_size, h//bin_size)\n",
    "\n",
    "            x = keras.layers.AveragePooling2D(pool_size=pool_strides_size, strides=pool_strides_size)(input_tensor)\n",
    "            x = keras.layers.Conv2D(128, 3, strides=2, padding='same')(x)\n",
    "            x = keras.layers.Lambda(lambda x: keras.backend.tf.image.resize_images(x, (w,h)))(x)\n",
    "\n",
    "            concat_list.append(x)\n",
    "\n",
    "        return keras.layers.concatenate(concat_list)\n",
    "\n",
    "    def get_scnn(self, input_layer):\n",
    "        \"\"\"Function to define the SCNN Model\"\"\"\n",
    "        lds_layer = self.conv_block(input_layer, 'conv', 32, (3, 3), strides = (2, 2))\n",
    "        lds_layer = self.conv_block(lds_layer, 'ds', 48, (3, 3), strides = (2, 2))\n",
    "        lds_layer = self.conv_block(lds_layer, 'ds', 64, (3, 3), strides = (2, 2))\n",
    "\n",
    "        gfe_layer = self.bottleneck_block(lds_layer, 64, (3, 3), t=6, strides=2, n=3)\n",
    "        gfe_layer = self.bottleneck_block(gfe_layer, 96, (3, 3), t=6, strides=2, n=3)\n",
    "        gfe_layer = self.bottleneck_block(gfe_layer, 128, (3, 3), t=6, strides=1, n=3)\n",
    "        gfe_layer = self.pyramid_pooling_block(gfe_layer, [2,4,6,8])\n",
    "\n",
    "        ff_layer1 = self.conv_block(lds_layer, 'conv', 128, (1,1), padding='same', strides= (1,1), relu=False)\n",
    "        ff_layer2 = keras.layers.UpSampling2D((4, 4))(gfe_layer)\n",
    "        ff_layer2 = keras.layers.SeparableConv2D(128, (3, 3), padding='same', strides = (1, 1), activation=None, dilation_rate=(4, 4))(ff_layer2)\n",
    "\n",
    "        ff_final = keras.layers.add([ff_layer1, ff_layer2])\n",
    "        ff_final = keras.layers.BatchNormalization()(ff_final)\n",
    "        ff_final = keras.layers.Activation('relu')(ff_final)\n",
    "\n",
    "        classifier = keras.layers.SeparableConv2D(128, (3, 3), padding='same', strides = (1, 1), name = 'DSConv1_classifier')(ff_final)\n",
    "        classifier = keras.layers.BatchNormalization()(classifier)\n",
    "        classifier = keras.layers.Activation('relu')(classifier)\n",
    "\n",
    "        classifier = keras.layers.SeparableConv2D(128, (3, 3), padding='same', strides = (1, 1), name = 'DSConv2_classifier')(classifier)\n",
    "        classifier = keras.layers.BatchNormalization()(classifier)\n",
    "        classifier = keras.layers.Activation('relu')(classifier)\n",
    "\n",
    "        classifier = self.conv_block(classifier, 'conv', self.COUNT_CATEGORIES, (1, 1), strides=(1, 1), padding='same', relu=True)\n",
    "\n",
    "        classifier = keras.layers.Dropout(0.3)(classifier)\n",
    "\n",
    "        classifier = keras.layers.UpSampling2D((8, 8))(classifier)\n",
    "        classifier = keras.layers.Activation('softmax')(classifier)\n",
    "\n",
    "        self.model = keras.Model(inputs = input_layer , outputs = classifier, name = 'Fast_SCNN')\n",
    "   \n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, imgs, shapes):\n",
    "        X = np.zeros((len(imgs), self.HEIGHT, self.WIDTH, self.COLORS), dtype=np.float32)\n",
    "        for i, img in enumerate(imgs):\n",
    "            X[i]      = self.normalize(img)\n",
    "            \n",
    "            #print(X[i])\n",
    "            plt.imshow(X[i])\n",
    "            plt.show()\n",
    "            \n",
    "            shapes[i] = np.array((img.shape[0], img.shape[1], 3))\n",
    "     \n",
    "        preds = self.model.predict(X)\n",
    "        \n",
    "        preds_t = preds[:, :, :, 1:2].reshape((preds.shape[0],preds.shape[1], preds.shape[2]))\n",
    "        \n",
    "        return (preds_t > 0.2).astype(np.uint8)\n",
    "        \n",
    "    def detect(self, imgs):\n",
    "        shapes = np.zeros((len(imgs), 3))\n",
    "        preds_t = self.predict(imgs, shapes)\n",
    "        res = []\n",
    "        \n",
    "        for j, (pred, shape) in enumerate(zip(preds_t, shapes)):\n",
    "            img = imgs[j]\n",
    "            preds_t_n = []\n",
    "            \n",
    "            pred = cv2.cvtColor(pred, cv2.COLOR_GRAY2RGB)*255\n",
    "\n",
    "            # clear mask\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15)) # find coef\n",
    "            pred = cv2.morphologyEx(pred, cv2.MORPH_OPEN, kernel)\n",
    "            pred = cv2.morphologyEx(pred, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "            pred = resize(pred, shape).astype(np.float32)\n",
    "\n",
    "            pred = cv2.cvtColor(pred*255, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            ret, thresh = cv2.threshold(pred.astype(np.uint8), 127, 255, 0)\n",
    "            contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            for i, c in enumerate(contours):\n",
    "#                 if (cv2.contourArea(c)/(img.shape[0]*img.shape[1])) < 0.0035:\n",
    "#                     print(\"BAD AREA\")\n",
    "#                     # detect center\n",
    "#                     M = cv2.moments(c)\n",
    "#                     cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "#                     cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    \n",
    "#                     refineSize = 256\n",
    "#                     x1 = cX - refineSize if cX - refineSize > 0 else 0\n",
    "#                     y1 = cY - refineSize if cY - refineSize > 0 else 0\n",
    "                    \n",
    "#                     x2 = cX + refineSize if cX + refineSize < img.shape[1] else img.shape[1]\n",
    "#                     y2 = cY + refineSize if cY + refineSize < img.shape[0] else img.shape[0]\n",
    "    \n",
    "#                     small_img = img[y1:y2, x1:x2]\n",
    "                    \n",
    "#                     small_shapes = np.zeros((len(imgs), 3))\n",
    "#                     preds_t = self.predict([small_img], small_shapes)\n",
    "#                     pred = cv2.cvtColor(preds_t[0], cv2.COLOR_GRAY2RGB)*255\n",
    "#                     pred = cv2.morphologyEx(pred, cv2.MORPH_OPEN, kernel)\n",
    "                    \n",
    "#                     pred = cv2.morphologyEx(pred, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "#                     pred = resize(pred, small_shapes[0]).astype(np.float32)\n",
    "\n",
    "#                     pred = cv2.cvtColor(pred*255, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "#                     ret, thresh = cv2.threshold(pred.astype(np.uint8), 127, 255, 0)\n",
    "#                     contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    \n",
    "#                     #cv2.drawContours(small_img, contours, -1, (0, 255, 0), 2)\n",
    "#                     #plt.imshow(small_img)\n",
    "#                     #plt.show()\n",
    "#                     if len(contours):\n",
    "#                         c = contours[0]\n",
    "#                         c = np.array([[[ic[0][0] + x1, ic[0][1] + y1]] for ic in c])\n",
    "                           \n",
    "                new_img = np.zeros(img.shape, np.uint8)\n",
    "                cv2.fillConvexPoly(new_img, np.array(cv2.convexHull(c), 'int32'), (255, 255, 255))\n",
    "                preds_t_n.append(new_img)\n",
    "            res.append(preds_t_n)\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def create_model(self):\n",
    "        # Input Layer\n",
    "        input_layer = keras.layers.Input(shape=((self.HEIGHT, self.WIDTH, self.COLORS)), name = 'input_layer')\n",
    "        self.model = self.get_scnn(input_layer)\n",
    "        \n",
    "        optimizer = keras.optimizers.SGD(momentum=0.9, lr=0.045)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    def prepare(self, dirpath, verbose=1):\n",
    "        self.DIRPATH = dirpath\n",
    "        self.prepare_data(verbose=verbose)\n",
    "        \n",
    "        self.train_gen = self.generator(mode=\"train\")\n",
    "        self.valid_gen = self.generator(mode=\"valid\")\n",
    "        \n",
    "    def fit(self, tmp_path='./tmp_scnn.h5', epochs=None, verbose=1):\n",
    "        self.callbacks = [\n",
    "            EarlyStopping(patience=20, verbose=verbose),\n",
    "            ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=verbose),\n",
    "            ModelCheckpoint(tmp_path, verbose=verbose, save_best_only=True, save_weights_only=True)\n",
    "        ]\n",
    "        return self.model.fit_generator(    self.train_gen, \n",
    "                      steps_per_epoch     = self.N_train, \n",
    "                      epochs              = epochs or self.EPOCHS, \n",
    "                      verbose             = verbose, \n",
    "                      callbacks           = self.callbacks, \n",
    "                      validation_data     = self.valid_gen, \n",
    "                      validation_steps    = self.N_valid)\n",
    "    \n",
    "    def load_last(self, tmp_path='./tmp_scnn.h5'):\n",
    "        self.model.load_weights(tmp_path)\n",
    "        \n",
    "    def save(self, path):\n",
    "        self.model.save(path)\n",
    "        return path\n",
    "\n",
    "    def load(self, path):\n",
    "        self.model = load_model(path)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QU9uETiqxOQW"
   },
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tkduqU9XQon4"
   },
   "source": [
    "![Fast-SCNN Architecture](https://github.com/DeepVoltaire/Fast-SCNN/raw/master/figures/fast-scnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBKpiNtQxMA6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0605 14:54:21.579193 140601561622144 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0605 14:54:21.586194 140601561622144 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0605 14:54:21.586694 140601561622144 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0605 14:54:21.599565 140601561622144 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0605 14:54:21.599872 140601561622144 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0605 14:54:22.571543 140601561622144 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0605 14:54:22.582996 140601561622144 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/moving_averages.py:212: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0605 14:54:24.160278 140601561622144 deprecation_wrapper.py:119] From /usr/local/lib64/python3.7/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 64, 32, 128), (None, 32, 64, 128), (None, 32, 64, 128), (None, 32, 64, 128), (None, 32, 64, 128)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7103bacf42ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-7791bac41fda>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m# Input Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLORS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'input_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.045\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7791bac41fda>\u001b[0m in \u001b[0;36mget_scnn\u001b[0;34m(self, input_layer)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mgfe_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgfe_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mgfe_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgfe_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mgfe_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyramid_pooling_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgfe_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mff_layer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlds_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7791bac41fda>\u001b[0m in \u001b[0;36mpyramid_pooling_block\u001b[0;34m(self, input_tensor, bin_sizes)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mconcat_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_scnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \"\"\"\n\u001b[0;32m--> 649\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    360\u001b[0m                              \u001b[0;34m'inputs with matching shapes '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                              \u001b[0;34m'except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                              'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 64, 32, 128), (None, 32, 64, 128), (None, 32, 64, 128), (None, 32, 64, 128), (None, 32, 64, 128)]"
     ]
    }
   ],
   "source": [
    "detector = SDetector()\n",
    "model = detector.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4692
    },
    "colab_type": "code",
    "id": "1bb-xo4uNhxV",
    "outputId": "939a9301-77e9-4dba-cc6f-a25c2af7d797",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.prepare(\"./dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.load_last(tmp_path='./tmp_scnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = detector.load_all_data(mode=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop\n",
    "X, y = X[:20], y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.model.evaluate(X, y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = detector.model.predict(X, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_t = (preds > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds[:, :, :, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get second class\n",
    "preds_t = preds_t[:, :, :, 1:2] \n",
    "y = y[:, :, :, 1:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
    "    \"\"\"Function to plot the results\"\"\"\n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "\n",
    "    has_mask = y[ix].max() > 0\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix, ...])\n",
    "    if has_mask:\n",
    "        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[0].set_title('Orig')\n",
    "\n",
    "    ax[1].imshow(y[ix].squeeze())\n",
    "    ax[1].set_title('Np')\n",
    "\n",
    "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n",
    "    if has_mask:\n",
    "        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[2].set_title('NP Predicted')\n",
    "    \n",
    "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)\n",
    "    if has_mask:\n",
    "        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[3].set_title('NP Predicted binary');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Check if training data looks all right\n",
    "plot_sample(X, y, preds, preds_t, ix=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_sample(X, y, preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TF 2.0 Fast-SCNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
